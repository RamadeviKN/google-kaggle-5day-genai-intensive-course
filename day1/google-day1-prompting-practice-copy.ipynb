{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-11T03:58:01.757807Z","iopub.execute_input":"2024-11-11T03:58:01.758252Z","iopub.status.idle":"2024-11-11T03:58:02.285089Z","shell.execute_reply.started":"2024-11-11T03:58:01.758200Z","shell.execute_reply":"2024-11-11T03:58:02.284019Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%pip install -U -q \"google-generativeai>=0.8.3\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T03:58:02.286516Z","iopub.execute_input":"2024-11-11T03:58:02.287098Z","iopub.status.idle":"2024-11-11T03:58:16.043451Z","shell.execute_reply.started":"2024-11-11T03:58:02.287047Z","shell.execute_reply":"2024-11-11T03:58:16.042121Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import google.generativeai as genai\nfrom IPython.display import HTML, Markdown, display","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T03:58:30.249818Z","iopub.execute_input":"2024-11-11T03:58:30.250262Z","iopub.status.idle":"2024-11-11T03:58:30.255130Z","shell.execute_reply.started":"2024-11-11T03:58:30.250219Z","shell.execute_reply":"2024-11-11T03:58:30.254017Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\ngenai.configure(api_key=GOOGLE_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T03:58:46.623225Z","iopub.execute_input":"2024-11-11T03:58:46.624362Z","iopub.status.idle":"2024-11-11T03:58:46.835515Z","shell.execute_reply.started":"2024-11-11T03:58:46.624289Z","shell.execute_reply":"2024-11-11T03:58:46.834052Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"flash = genai.GenerativeModel('gemini-1.5-flash')\nresponse = flash.generate_content(\"Explain AI to me like I'm a kid.\")\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T03:59:27.601750Z","iopub.execute_input":"2024-11-11T03:59:27.602639Z","iopub.status.idle":"2024-11-11T03:59:29.253977Z","shell.execute_reply.started":"2024-11-11T03:59:27.602594Z","shell.execute_reply":"2024-11-11T03:59:29.252837Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Markdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T03:59:52.355316Z","iopub.execute_input":"2024-11-11T03:59:52.356145Z","iopub.status.idle":"2024-11-11T03:59:52.364264Z","shell.execute_reply.started":"2024-11-11T03:59:52.356095Z","shell.execute_reply":"2024-11-11T03:59:52.363211Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"chat = flash.start_chat(history=[])\nresponse = chat.send_message('Hello! My name is Ramadevi.')\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T04:00:45.368543Z","iopub.execute_input":"2024-11-11T04:00:45.369869Z","iopub.status.idle":"2024-11-11T04:00:46.247344Z","shell.execute_reply.started":"2024-11-11T04:00:45.369823Z","shell.execute_reply":"2024-11-11T04:00:46.246172Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"response = chat.send_message('Can you tell something interesting about Python?')\nprint(response.text)\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T04:01:49.012762Z","iopub.execute_input":"2024-11-11T04:01:49.013451Z","iopub.status.idle":"2024-11-11T04:01:51.319306Z","shell.execute_reply.started":"2024-11-11T04:01:49.013391Z","shell.execute_reply":"2024-11-11T04:01:51.318258Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for model in genai.list_models():\n  print(model.name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T04:02:27.642289Z","iopub.execute_input":"2024-11-11T04:02:27.643247Z","iopub.status.idle":"2024-11-11T04:02:28.120377Z","shell.execute_reply.started":"2024-11-11T04:02:27.643201Z","shell.execute_reply":"2024-11-11T04:02:28.119326Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for model in genai.list_models():\n  if model.name == 'models/gemini-1.5-flash':\n    print(model)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T04:02:54.130590Z","iopub.execute_input":"2024-11-11T04:02:54.131549Z","iopub.status.idle":"2024-11-11T04:02:54.556362Z","shell.execute_reply.started":"2024-11-11T04:02:54.131504Z","shell.execute_reply":"2024-11-11T04:02:54.555335Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"short_model = genai.GenerativeModel(\n    'gemini-1.5-flash',\n    generation_config=genai.GenerationConfig(max_output_tokens=200))\n\nresponse = short_model.generate_content('Write a 1000 word essay on the importance of mindfulness in modern society.')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T04:04:00.575324Z","iopub.execute_input":"2024-11-11T04:04:00.576333Z","iopub.status.idle":"2024-11-11T04:04:02.302056Z","shell.execute_reply.started":"2024-11-11T04:04:00.576269Z","shell.execute_reply":"2024-11-11T04:04:02.300959Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"response = short_model.generate_content('Write a short poem on women empowerment in modern era')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T04:05:06.356848Z","iopub.execute_input":"2024-11-11T04:05:06.357353Z","iopub.status.idle":"2024-11-11T04:05:07.504483Z","shell.execute_reply.started":"2024-11-11T04:05:06.357310Z","shell.execute_reply":"2024-11-11T04:05:07.503483Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"high_temp_model = genai.GenerativeModel(\n    'gemini-1.5-flash',\n    generation_config=genai.GenerationConfig(temperature=2.0))\n\nfor _ in range(5):\n  response = high_temp_model.generate_content('Pick a random colour... (answer in a single word)')\n  if response.parts:\n    print(response.text, '-' * 25)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T04:06:04.430166Z","iopub.execute_input":"2024-11-11T04:06:04.431234Z","iopub.status.idle":"2024-11-11T04:06:08.912907Z","shell.execute_reply.started":"2024-11-11T04:06:04.431190Z","shell.execute_reply":"2024-11-11T04:06:08.911800Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"low_temp_model = genai.GenerativeModel(\n    'gemini-1.5-flash',\n    generation_config=genai.GenerationConfig(temperature=0.0))\n\nfor _ in range(5):\n  response = low_temp_model.generate_content('Pick a random colour... (answer in a single word)')\n  if response.parts:\n    print(response.text, '-' * 25)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T04:06:34.962420Z","iopub.execute_input":"2024-11-11T04:06:34.963597Z","iopub.status.idle":"2024-11-11T04:06:36.041961Z","shell.execute_reply.started":"2024-11-11T04:06:34.963552Z","shell.execute_reply":"2024-11-11T04:06:36.040187Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = genai.GenerativeModel(\n    'gemini-1.5-flash-001',\n    generation_config=genai.GenerationConfig(\n        # These are the default values for gemini-1.5-flash-001.\n        temperature=1.0,\n        top_k=64,\n        top_p=0.95,\n    ))\n\nstory_prompt = \"You are a creative writer. Write a short story about a dinosaur who wants to be a cop.\"\nresponse = model.generate_content(story_prompt)\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T04:07:44.070425Z","iopub.execute_input":"2024-11-11T04:07:44.071237Z","iopub.status.idle":"2024-11-11T04:07:47.424379Z","shell.execute_reply.started":"2024-11-11T04:07:44.071191Z","shell.execute_reply":"2024-11-11T04:07:47.423294Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#zero shot prompts\nmodel = genai.GenerativeModel(\n    'gemini-1.5-flash-001',\n    generation_config=genai.GenerationConfig(\n        temperature=0.1,\n        top_p=1,\n        max_output_tokens=5,\n    ))\n\nzero_shot_prompt = \"\"\"Classify movie reviews as POSITIVE, NEUTRAL or NEGATIVE.\nReview: \"Her\" is a disturbing study revealing the direction\nhumanity is headed if AI is allowed to keep evolving,\nunchecked. I wish there were more movies like this masterpiece.\nSentiment: \"\"\"\n\nresponse = model.generate_content(zero_shot_prompt)\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T04:09:29.674912Z","iopub.execute_input":"2024-11-11T04:09:29.675360Z","iopub.status.idle":"2024-11-11T04:09:30.072013Z","shell.execute_reply.started":"2024-11-11T04:09:29.675320Z","shell.execute_reply":"2024-11-11T04:09:30.070936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import enum\n\nclass Sentiment(enum.Enum):\n    POSITIVE = \"positive\"\n    NEUTRAL = \"neutral\"\n    NEGATIVE = \"negative\"\n\n\nmodel = genai.GenerativeModel(\n    'gemini-1.5-flash-001',\n    generation_config=genai.GenerationConfig(\n        response_mime_type=\"text/x.enum\",\n        response_schema=Sentiment\n    ))\n\nresponse = model.generate_content(zero_shot_prompt)\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T04:10:16.846819Z","iopub.execute_input":"2024-11-11T04:10:16.848377Z","iopub.status.idle":"2024-11-11T04:10:17.598484Z","shell.execute_reply.started":"2024-11-11T04:10:16.848284Z","shell.execute_reply":"2024-11-11T04:10:17.597316Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = genai.GenerativeModel(\n    'gemini-1.5-flash-latest',\n    generation_config=genai.GenerationConfig(\n        temperature=0.1,\n        top_p=1,\n        max_output_tokens=250,\n    ))\n\nfew_shot_prompt = \"\"\"Parse a customer's pizza order into valid JSON:\n\nEXAMPLE:\nI want a small pizza with cheese, tomato sauce, and pepperoni.\nJSON Response:\n```\n{\n\"size\": \"small\",\n\"type\": \"normal\",\n\"ingredients\": [\"cheese\", \"tomato sauce\", \"peperoni\"]\n}\n```\n\nEXAMPLE:\nCan I get a large pizza with tomato sauce, basil and mozzarella\nJSON Response:\n```\n{\n\"size\": \"large\",\n\"type\": \"normal\",\n\"ingredients\": [\"tomato sauce\", \"basil\", \"mozzarella\"]\n}\n\nORDER:\n\"\"\"\n\ncustomer_order = \"Give me a small with peperoni & pineapple\"\n\n\nresponse = model.generate_content([few_shot_prompt, customer_order])\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T04:11:39.722155Z","iopub.execute_input":"2024-11-11T04:11:39.723175Z","iopub.status.idle":"2024-11-11T04:11:40.176433Z","shell.execute_reply.started":"2024-11-11T04:11:39.723131Z","shell.execute_reply":"2024-11-11T04:11:40.175198Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import typing_extensions as typing\n\nclass PizzaOrder(typing.TypedDict):\n    size: str\n    ingredients: list[str]\n    type: str\n\n\nmodel = genai.GenerativeModel(\n    'gemini-1.5-flash-latest',\n    generation_config=genai.GenerationConfig(\n        temperature=0.1,\n        response_mime_type=\"application/json\",\n        response_schema=PizzaOrder,\n    ))\n\nresponse = model.generate_content(\"Can I have a large dessert pizza with apple and chocolate\")\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T04:12:31.310301Z","iopub.execute_input":"2024-11-11T04:12:31.310763Z","iopub.status.idle":"2024-11-11T04:12:31.806768Z","shell.execute_reply.started":"2024-11-11T04:12:31.310720Z","shell.execute_reply":"2024-11-11T04:12:31.805578Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Chain of thought prompting\n\nprompt = \"\"\"When I was 6 years old, my partner was 3 times my age. Now, I\nam 20 years old. How old is my partner? Return the answer immediately.\"\"\"\n\nmodel = genai.GenerativeModel('gemini-1.5-flash-latest')\nresponse = model.generate_content(prompt)\n\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T04:13:20.508138Z","iopub.execute_input":"2024-11-11T04:13:20.509093Z","iopub.status.idle":"2024-11-11T04:13:20.899252Z","shell.execute_reply.started":"2024-11-11T04:13:20.509053Z","shell.execute_reply":"2024-11-11T04:13:20.898169Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt = \"\"\"When I was 4 years old, my partner was 3 times my age. Now,\nI am 20 years old. How old is my partner? Let's think step by step.\"\"\"\n\nresponse = model.generate_content(prompt)\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T04:13:39.778165Z","iopub.execute_input":"2024-11-11T04:13:39.778585Z","iopub.status.idle":"2024-11-11T04:13:40.523037Z","shell.execute_reply.started":"2024-11-11T04:13:39.778545Z","shell.execute_reply":"2024-11-11T04:13:40.521948Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_instructions = \"\"\"\nSolve a question answering task with interleaving Thought, Action, Observation steps. Thought can reason about the current situation,\nObservation is understanding relevant information from an Action's output and Action can be one of three types:\n (1) <search>entity</search>, which searches the exact entity on Wikipedia and returns the first paragraph if it exists. If not, it\n     will return some similar entities to search and you can try to search the information from those topics.\n (2) <lookup>keyword</lookup>, which returns the next sentence containing keyword in the current context. This only does exact matches,\n     so keep your searches short.\n (3) <finish>answer</finish>, which returns the answer and finishes the task.\n\"\"\"\n\nexample1 = \"\"\"Question\nMusician and satirist Allie Goertz wrote a song about the \"The Simpsons\" character Milhouse, who Matt Groening named after who?\n\nThought 1\nThe question simplifies to \"The Simpsons\" character Milhouse is named after who. I only need to search Milhouse and find who it is named after.\n\nAction 1\n<search>Milhouse</search>\n\nObservation 1\nMilhouse Mussolini Van Houten is a recurring character in the Fox animated television series The Simpsons voiced by Pamela Hayden and created by Matt Groening.\n\nThought 2\nThe paragraph does not tell who Milhouse is named after, maybe I can look up \"named after\".\n\nAction 2\n<lookup>named after</lookup>\n\nObservation 2\nMilhouse was named after U.S. president Richard Nixon, whose middle name was Milhous.\n\nThought 3\nMilhouse was named after U.S. president Richard Nixon, so the answer is Richard Nixon.\n\nAction 3\n<finish>Richard Nixon</finish>\n\"\"\"\n\nexample2 = \"\"\"Question\nWhat is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?\n\nThought 1\nI need to search Colorado orogeny, find the area that the eastern sector of the Colorado orogeny extends into, then find the elevation range of the area.\n\nAction 1\n<search>Colorado orogeny</search>\n\nObservation 1\nThe Colorado orogeny was an episode of mountain building (an orogeny) in Colorado and surrounding areas.\n\nThought 2\nIt does not mention the eastern sector. So I need to look up eastern sector.\n\nAction 2\n<lookup>eastern sector</lookup>\n\nObservation 2\nThe eastern sector extends into the High Plains and is called the Central Plains orogeny.\n\nThought 3\nThe eastern sector of Colorado orogeny extends into the High Plains. So I need to search High Plains and find its elevation range.\n\nAction 3\n<search>High Plains</search>\n\nObservation 3\nHigh Plains refers to one of two distinct land regions\n\nThought 4\nI need to instead search High Plains (United States).\n\nAction 4\n<search>High Plains (United States)</search>\n\nObservation 4\nThe High Plains are a subregion of the Great Plains. From east to west, the High Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130m).\n\nThought 5\nHigh Plains rise in elevation from around 1,800 to 7,000 ft, so the answer is 1,800 to 7,000 ft.\n\nAction 5\n<finish>1,800 to 7,000 ft</finish>\n\"\"\"\n\n# Come up with more examples yourself, or take a look through https://github.com/ysymyth/ReAct/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T04:15:37.230789Z","iopub.execute_input":"2024-11-11T04:15:37.231320Z","iopub.status.idle":"2024-11-11T04:15:37.239882Z","shell.execute_reply.started":"2024-11-11T04:15:37.231256Z","shell.execute_reply":"2024-11-11T04:15:37.238775Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"question = \"\"\"Question\nWho was the youngest author listed on the transformers NLP paper?\n\"\"\"\n\nmodel = genai.GenerativeModel('gemini-1.5-flash-latest')\nreact_chat = model.start_chat()\n\n# You will perform the Action, so generate up to, but not including, the Observation.\nconfig = genai.GenerationConfig(stop_sequences=[\"\\nObservation\"])\n\nresp = react_chat.send_message(\n    [model_instructions, example1, example2, question],\n    generation_config=config)\nprint(resp.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T04:15:57.723197Z","iopub.execute_input":"2024-11-11T04:15:57.724244Z","iopub.status.idle":"2024-11-11T04:16:00.853476Z","shell.execute_reply.started":"2024-11-11T04:15:57.724185Z","shell.execute_reply":"2024-11-11T04:16:00.852333Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"observation = \"\"\"Observation 1\n[1706.03762] Attention Is All You Need\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\nWe propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.\n\"\"\"\nresp = react_chat.send_message(observation, generation_config=config)\nprint(resp.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T04:16:44.058922Z","iopub.execute_input":"2024-11-11T04:16:44.059411Z","iopub.status.idle":"2024-11-11T04:16:44.758956Z","shell.execute_reply.started":"2024-11-11T04:16:44.059368Z","shell.execute_reply":"2024-11-11T04:16:44.757779Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Generate Code\n\nmodel = genai.GenerativeModel(\n    'gemini-1.5-flash-latest',\n    generation_config=genai.GenerationConfig(\n        temperature=1,\n        top_p=1,\n        max_output_tokens=1024,\n    ))\n\n# Gemini 1.5 models are very chatty, so it helps to specify they stick to the code.\ncode_prompt = \"\"\"\nWrite a Python function to calculate the factorial of a number. No explanation, provide only the code.\n\"\"\"\n\nresponse = model.generate_content(code_prompt)\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T04:17:30.909848Z","iopub.execute_input":"2024-11-11T04:17:30.910263Z","iopub.status.idle":"2024-11-11T04:17:31.704820Z","shell.execute_reply.started":"2024-11-11T04:17:30.910224Z","shell.execute_reply":"2024-11-11T04:17:31.703803Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = genai.GenerativeModel(\n    'gemini-1.5-flash-latest',\n    tools='code_execution')\n\ncode_exec_prompt = \"\"\"\nCalculate the sum of the first 14 prime numbers. Only consider the even primes, and make sure you get them all.\n\"\"\"\n\nresponse = model.generate_content(code_exec_prompt)\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T04:18:15.026886Z","iopub.execute_input":"2024-11-11T04:18:15.027309Z","iopub.status.idle":"2024-11-11T04:18:15.901423Z","shell.execute_reply.started":"2024-11-11T04:18:15.027249Z","shell.execute_reply":"2024-11-11T04:18:15.900461Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for part in response.candidates[0].content.parts:\n  print(part)\n  print(\"-----\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T04:18:46.810074Z","iopub.execute_input":"2024-11-11T04:18:46.810621Z","iopub.status.idle":"2024-11-11T04:18:46.817724Z","shell.execute_reply.started":"2024-11-11T04:18:46.810576Z","shell.execute_reply":"2024-11-11T04:18:46.816483Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"file_contents = !curl https://raw.githubusercontent.com/magicmonty/bash-git-prompt/refs/heads/master/gitprompt.sh\n\nexplain_prompt = f\"\"\"\nPlease explain what this file does at a very high level. What is it, and why would I use it?\n\n```\n{file_contents}\n```\n\"\"\"\n\nmodel = genai.GenerativeModel('gemini-1.5-flash-latest')\n\nresponse = model.generate_content(explain_prompt)\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T04:19:21.190171Z","iopub.execute_input":"2024-11-11T04:19:21.190674Z","iopub.status.idle":"2024-11-11T04:19:25.015905Z","shell.execute_reply.started":"2024-11-11T04:19:21.190624Z","shell.execute_reply":"2024-11-11T04:19:25.014926Z"}},"outputs":[],"execution_count":null}]}